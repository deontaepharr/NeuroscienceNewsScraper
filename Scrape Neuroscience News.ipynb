{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    \n",
    "    def __init__(self, title, body_text, tags, image):\n",
    "        self.title = title\n",
    "        self.body_text = body_text\n",
    "        self.tags = tags\n",
    "        self.image = image\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Article -- (Title: {},\\n\\nBody Text: {},\\n\\nTags: {},\\n\\nImage: {})\" \\\n",
    "                .format(self.title, self.body_text, self.tags, self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleScrape:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.headers = requests.utils.default_headers()\n",
    "        self.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n",
    "        })\n",
    "\n",
    "    def scrape_article(self, url):\n",
    "        r = requests.get(url, self.headers)\n",
    "        raw_html = r.content\n",
    "        soup_html = BeautifulSoup(raw_html, 'html.parser')\n",
    "        \n",
    "        # Commence Article Scraping\n",
    "        a_title = self.__retrieve_article_title(soup_html)\n",
    "        a_p = self.__retrieve_p_elements(soup_html)\n",
    "        a_tags = self.__retrieve_article_tags(soup_html)\n",
    "        a_image = self.__retrieve_article_image(soup_html)\n",
    "        \n",
    "        article = Article(a_title, a_p, a_tags, a_image)\n",
    "\n",
    "        return article\n",
    "\n",
    "    def __retrieve_article_title(self, soup_html):\n",
    "        return soup_html.find('title').text\n",
    "\n",
    "    def __retrieve_p_elements(self, soup_html, get_text=False):\n",
    "        if get_text:\n",
    "            return [p.text for p in soup_html.findAll('p')][:-3]\n",
    "\n",
    "        return soup_html.findAll('p')[:-3]\n",
    "\n",
    "    def __retrieve_article_tags(self, soup_html):\n",
    "        return soup_html.findAll(\"span\", class_=\"cb-element\")\n",
    "\n",
    "    def __retrieve_article_image(self, soup_html):\n",
    "        img_dict = {}\n",
    "        img_tag = soup_html.find(class_='wp-caption')\n",
    "\n",
    "        # Information to retrieve\n",
    "        img_link = img_tag.a['href']\n",
    "        img_alt = img_tag.img['alt']\n",
    "        img_text = img_tag.text\n",
    "\n",
    "        img_dict['link'] = img_link\n",
    "        img_dict['alt'] = img_alt\n",
    "        img_dict['text'] = img_text\n",
    "\n",
    "        return img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://neurosciencenews.com/moving-object-background-14424/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_scraper = ArticleScrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = a_scraper.scrape_article(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why are we able to see moving objects against moving backgrounds? - Neuroscience News'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p><em><strong>Summary: </strong>The human brain can desensitize background motion and focus on smaller moving objects in the foreground as a result of activity in the middle temporal visual area. However, our ability to pick out smaller objects changes over time. Younger people are better at picking out foreground objects moving, while those over 65 have heightened awareness of objects moving in the background.</em></p>,\n",
       " <p><strong>Source: </strong>University of Rochester</p>,\n",
       " <p><strong>Visual motion is an important source of information for separating objects from their backgrounds.</strong></p>,\n",
       " <p>A spider camouflaged against a branch, for instance, immediately loses its invisibility once it starts moving. A friend you’re trying to spot in a crowded airport terminal is more distinguishable once she begins waving her hands.</p>,\n",
       " <p>While the process of separating an object from a background is seemingly effortless, researchers don’t know how our visual system manages to rapidly pick out and segregate moving objects from their backgrounds.</p>,\n",
       " <p>According to new research from scientists at the University of Rochester, one reason human beings are good at discerning smaller moving objects in the foreground is that the brain becomes desensitized to the motion in the larger background. Conversely, when a person’s brain is more sensitive to background motion, the negative trade-off is that she will be less sensitive to smaller foreground objects. The research, published in the journal <em>Nature Communications</em>, could lead to new training programs for elderly adults and patients with conditions such as schizophrenia, which has been linked to weaker motion segregation.</p>,\n",
       " <p>“The human brain cannot possibly process all of the information around us,” says Duje Tadin, a professor of brain and cognitive sciences at Rochester and the lead author of the study. </p>,\n",
       " <p>“Being less sensitive to things that are less important makes the brain more efficient and faster at accomplishing the more important tasks.”</p>,\n",
       " <p>Take driving for instance. As the background scenery whizzes by, it is imperative that a driver see and avoid cars, pedestrians, and other objects on the road.</p>,\n",
       " <p>There are two basic ways the brain can distinguish such objects from moving backgrounds. It can enhance the objects that matter; or, it can suppress the background, and, by virtue of this suppression, enhance the objects. The latter is “the more efficient option,” Tadin says. “Think about trying to have a conversation in a room with high background noise. It is more effective to find a way to turn off the noise than it is to just try speaking more loudly.”</p>,\n",
       " <p>While these strategies are not the only ones the brain uses to highlight moving objects–attention is another factor, for instance–previous research from Tadin’s lab found a link between IQ and an ability to suppress background motion. The researchers speculated that in healthy, young people, a region in the brain called the middle temporal visual area (MT) is responsible for this suppression.</p>,\n",
       " <p>In order to test people’s ability to identify moving objects on a moving background, the researchers showed study participants moving textured patterns. Within the textured background, there was a smaller patterned object moving in the direction opposite from the background. The participants were instructed to report either the location or the shape of the smaller patterned object.</p>,\n",
       " <p>The researchers found that younger adults were better at seeing smaller moving objects in the foreground and worse at seeing background motion. Older adults–participants aged 65 and above–were the opposite. They were poorer at seeing the smaller moving objects because they had a heightened awareness of the backdrop against which the objects moved. Younger adults took on average 20 milliseconds to pick out the moving objects, and older adults took about 30 milliseconds.</p>,\n",
       " <p>While both groups were efficient at the task, taking only a fraction of a second to detect the movement of the object against the background, “those extra milliseconds could make a big difference,” says Woon Ju Park, a former postdoctoral associate in Tadin’s lab and currently a research associate at the University of Washington. “Think about things that matter for your survival.” A split second could mean the difference between hitting or avoiding a pedestrian, or it could be just enough time to lose sight of a rambunctious child. In the case of the animal world, it could mean the difference between life and death.</p>,\n",
       " <p>“Think of an animal in the wild,” Park says. “If it sees a moving object, that could either be lunch for the animal or something that could eat that animal for lunch. Animals are really good at camouflage, but even the best camouflage pulls apart with motion.”</p>,\n",
       " <p class=\"wp-caption-text\" id=\"caption-attachment-57775\">Animals camouflaged against their background, like this Florida leopard frog, become easier to detect once they start moving. New research from Rochester scientists explores why human beings are good at discerning moving objects and how we can train our brains to be better at this as we age. The image is credited to University of Rochester photo / J. Adam Fenster.</p>,\n",
       " <p>The researchers speculate that older adults have impaired motion segregation because as people age, their vision changes and becomes “noisier.” As an adaptive mechanism, the aging brain then might prioritize integrating motion information in general over suppressing and segmenting background from the foreground. The results also suggest that people with psychiatric conditions such as schizophrenia–associated with similar “noisier” visual systems–might also experience the trade-off between integration and segregation.</p>,\n",
       " <p>Although the research shows that the ability to detect moving objects against a moving background decreases with age, the research also offers some good news for older adults.</p>,\n",
       " <p>“With training, we can make older adults be more like younger adults,” Tadin says.</p>,\n",
       " <p><iframe allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" frameborder=\"0\" height=\"315\" src=\"https://www.youtube.com/embed/1h3eH-FrEGU\" width=\"560\"></iframe><br/>\n",
       " <em>Visual motion is an important source of information for separating objects from their backgrounds. Credit: University of Rochester.</em></p>,\n",
       " <p>The researchers found that older adults could train their brains to process motion more like younger adults by practicing visual segmentation of moving objects. Older participants performed the study task for four weeks, with four sessions per week, and became quicker at the task, narrowing the gap in performance with their younger counterparts. Surprisingly, the researchers found, the older participants who underwent training did not, in fact, get better at seeing the smaller moving object; their ability to see the object was just as good as it was at the beginning of the training. What changed with training was that the older adults became less sensitive to the background motion, just like younger adults.</p>,\n",
       " <p>“Most of the time when you train something in the brain, things get better,” Tadin says. “This is a case where, with training, you get better at seeing objects, while at the same time get worse at seeing the background. This showed us that these two things are really integrally connected because when we affected one, the other one also changed.”</p>,\n",
       " <p><strong>Source:</strong><br/>\n",
       " <a href=\"https://www.rochester.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Rochester</a><br/>\n",
       " <strong>Media Contacts: </strong><br/>\n",
       " Lindsey Valich – University of Rochester<br/>\n",
       " <strong>Image Source:</strong><br/>\n",
       " The image is credited to University of Rochester photo / J. Adam Fenster.</p>,\n",
       " <p><strong>Original Research: </strong>Open access<br/>\n",
       " <a href=\"https://doi.org/10.1038/s41467-019-10653-8\" rel=\"noopener noreferrer\" target=\"_blank\">“Spatial suppression promotes rapid figure-ground segmentation of moving objects”.</a> Duje Tadin, Woon Ju Park, Kevin C. Dieter, Michael D. Melnick, Joseph S. Lappin &amp; Randolph Blake.<br/>\n",
       " <em>Nature Communications</em>. doi:<a href=\"https://doi.org/10.1038/s41467-019-10653-8\" rel=\"noopener noreferrer\" target=\"_blank\">10.1038/s41467-019-10653-8</a></p>,\n",
       " <p><strong>Abstract</strong></p>,\n",
       " <p><strong>Spatial suppression promotes rapid figure-ground segmentation of moving objects</strong> </p>,\n",
       " <p>Segregation of objects from their backgrounds is a fundamental visual function and one that is particularly effective when objects are in motion. Theoretically, suppressive center-surround mechanisms are well suited for accomplishing motion segregation. This longstanding hypothesis, however, has received limited empirical support. We report converging correlational and causal evidence that spatial suppression of background motion signals is critical for rapid segmentation of moving objects. Motion segregation ability is strongly predicted by both individual and stimulus-driven variations in spatial suppression strength. Moreover, aging-related superiority in perceiving background motion is associated with profound impairments in motion segregation. This segregation deficit is alleviated via perceptual learning, but only when motion segregation training also causes decreased sensitivity to background motion. We argue that perceptual insensitivity to large moving stimuli effectively implements background subtraction, which, in turn, enhances the visibility of moving objects and accounts for the observed link between spatial suppression and motion segregation.</p>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.body_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
